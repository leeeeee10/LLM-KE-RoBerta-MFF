{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b4c0976-b95d-4e8e-aa0c-21e3b543ef6a",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-04-22T11:31:42.558113Z",
     "iopub.status.busy": "2025-04-22T11:31:42.557838Z",
     "iopub.status.idle": "2025-04-22T11:31:44.017468Z",
     "shell.execute_reply": "2025-04-22T11:31:44.016874Z",
     "shell.execute_reply.started": "2025-04-22T11:31:42.558093Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No', 'Title', 'Abstract', 'Keywords', 'Tags']\n",
      "训练集包含标签: [0, 1, 2, 3, 4, 5, 6]\n",
      "验证集包含标签: [0, 1, 2, 3, 4, 5, 6]\n",
      "测试集包含标签: [0, 1, 2, 3, 4, 5, 6]\n",
      "\n",
      "处理完成！\n",
      "训练集样本数: 8902\n",
      "验证集样本数: 1908\n",
      "测试集样本数: 1907\n"
     ]
    }
   ],
   "source": [
    "#确保每个集有每个类别的数据\n",
    "#pip install scikit-multilearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "# 定义标签列表和创建标签到数字的映射\n",
    "tags_list = [\n",
    "    \"传感器与仪器\",\n",
    "    \"生命健康技术\",\n",
    "    \"新材料科技\",\n",
    "    \"新能源与动力\",\n",
    "    \"数字智能技术\",\n",
    "    \"智能制造与装备\",\n",
    "    \"其它\"   \n",
    "]\n",
    "tag2id = {tag: idx for idx, tag in enumerate(tags_list)}\n",
    "\n",
    "# 读取CSV文件\n",
    "df = pd.read_csv('result_data_7.csv')  # 修改为你的CSV文件路径\n",
    "print(df.columns.tolist())  # 查看所有实际列名\n",
    "\n",
    "# 处理标签列（支持中英文逗号分隔）\n",
    "def convert_tags(tags_str):\n",
    "    tags = re.split(r'[，,]+', tags_str)\n",
    "    tags = [tag.strip() for tag in tags if tag.strip()]\n",
    "    tag_ids = []\n",
    "    for tag in tags:\n",
    "        if tag in tag2id:\n",
    "            tag_ids.append(str(tag2id[tag]))\n",
    "        else:\n",
    "            raise ValueError(f\"发现未知标签: '{tag}'，请检查数据一致性\")\n",
    "    return tag_ids\n",
    "\n",
    "df['tags_ids'] = df['Tags'].apply(convert_tags)\n",
    "\n",
    "# 拼接文本列并清理\n",
    "text_columns = ['Title', 'Abstract', 'Keywords']\n",
    "for col in text_columns:\n",
    "    df[col] = df[col].fillna('')\n",
    "\n",
    "df['text'] = df[text_columns].apply(lambda x: ' '.join(x), axis=1)\n",
    "df['text'] = df['text'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())\n",
    "\n",
    "# 将标签转换为二进制矩阵\n",
    "y = np.zeros((len(df), len(tags_list)), dtype=int)\n",
    "for i, tags in enumerate(df['tags_ids']):\n",
    "    for tag_id in tags:\n",
    "        y[i, int(tag_id)] = 1\n",
    "\n",
    "# 使用多标签分层抽样划分数据集\n",
    "X = df.index.values.reshape(-1, 1)  # 使用索引作为特征\n",
    "\n",
    "# 第一次划分：70%训练集，30%临时集\n",
    "X_train, y_train, X_temp, y_temp = iterative_train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# 第二次划分：将临时集分为15%验证集和15%测试集\n",
    "X_val, y_val, X_test, y_test = iterative_train_test_split(X_temp, y_temp, test_size=0.5)\n",
    "\n",
    "# 获取对应的数据子集\n",
    "train_df = df.iloc[X_train.flatten()]\n",
    "val_df = df.iloc[X_val.flatten()]\n",
    "test_df = df.iloc[X_test.flatten()]\n",
    "\n",
    "# 保存数据集到TXT文件\n",
    "def save_dataset(df, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for text, tags in zip(df['text'], df['tags_ids']):\n",
    "            f.write(f\"{text}\\t{','.join(tags)}\\n\")\n",
    "\n",
    "save_dataset(train_df, 'train.txt')\n",
    "save_dataset(val_df, 'dev.txt')\n",
    "save_dataset(test_df, 'test.txt')\n",
    "\n",
    "# 验证每个子集的标签分布\n",
    "def check_coverage(df_set, set_name):\n",
    "    existing_tags = set()\n",
    "    for tags in df_set['tags_ids']:\n",
    "        for tag in tags:\n",
    "            existing_tags.add(int(tag))\n",
    "    print(f\"{set_name}包含标签: {sorted(existing_tags)}\")\n",
    "\n",
    "check_coverage(train_df, \"训练集\")\n",
    "check_coverage(val_df, \"验证集\")\n",
    "check_coverage(test_df, \"测试集\")\n",
    "\n",
    "print(\"\\n处理完成！\")\n",
    "print(f\"训练集样本数: {len(train_df)}\")\n",
    "print(f\"验证集样本数: {len(val_df)}\")\n",
    "print(f\"测试集样本数: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69143f20-aff4-40c3-be20-e06b80c4b78c",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-05-18T07:26:26.996517Z",
     "iopub.status.busy": "2025-05-18T07:26:26.996187Z",
     "iopub.status.idle": "2025-05-18T07:26:29.108878Z",
     "shell.execute_reply": "2025-05-18T07:26:29.108295Z",
     "shell.execute_reply.started": "2025-05-18T07:26:26.996499Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据量: 12717\n",
      "有效数据量: 12717\n",
      "\n",
      "处理完成！样本分布：\n",
      "训练集: 8902条\n",
      "验证集: 1906条\n",
      "测试集: 1909条\n",
      "\n",
      "格式验证：\n"
     ]
    }
   ],
   "source": [
    "#针对新能源与动力与智能制造装备做过滤\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "# ==================== 需要过滤的高频词列表 ====================\n",
    "HIGH_FREQ_WORDS = {\n",
    "    '机器', '汽油', '气油', '能', '控', '系', '统', '技', '电', '动', '车', \n",
    "    '测', '试', '装', '备', '产', '造', '究', '物', '理', '源', '气', '管', \n",
    "    '化', '铁', '金', '钢', '高', '带', '液', '修', '强', '和', '中', '材', \n",
    "    '设', '托', '体', '氧', '于', '特', '地', '成', '型', '铝', '该', '光', \n",
    "    '继', '抗', '孔', '养', '上', '列', '头', '智', '应', '面', '基', '箱', \n",
    "    '自', '台', '人', '属', '空', '瓶', '种', '锁', '收', '片', '口', '米', \n",
    "    '联', '频', '断', '息', '计', '别', '活', '验', '瞬', '制', '据', '处', \n",
    "    '然', '保', '废', '配', '蒸', '数', '层', '绿', '向', '清', '盐', '压', \n",
    "    '加', '号', '发', '质', '池', '油', '氟', '震', '长', '集', '输', '感', \n",
    "    '水', '性', '警', '轮', '学', '挡', '建', '轴', '络', '内', '环', '温', \n",
    "    '检', '式', '品', '结', '合', '信','项目', '实现', '方法', '技术', '研究', \n",
    "    '具有', '提出', '采用', '通过','成果', '所述', '结果', '包括', '提供', \n",
    "    '解决', '评价', '中国', '系统','应用', '影响', '形成','问题','重庆市','创新',\n",
    "    '进行','关键','主要','国家'\n",
    "}\n",
    "\n",
    "# ==================== 核心过滤函数 ====================\n",
    "def remove_high_freq(text):\n",
    "    \"\"\"增强文本清洗逻辑\"\"\"\n",
    "    # 移除特殊空白字符\n",
    "    text = re.sub(r'[\\t\\n\\r]', ' ', text)\n",
    "    # 过滤高频词\n",
    "    for word in HIGH_FREQ_WORDS:\n",
    "        text = text.replace(word, '')\n",
    "    # 合并连续空格\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# ==================== 数据加载与预处理 ====================\n",
    "tags_list = [\n",
    "    \"传感器与仪器\",\n",
    "    \"生命健康技术\",\n",
    "    \"新材料科技\",\n",
    "    \"新能源与动力\",\n",
    "    \"数字智能技术\",\n",
    "    \"智能制造与装备\",\n",
    "    \"其它\"   \n",
    "]\n",
    "tag2id = {tag: idx for idx, tag in enumerate(tags_list)}\n",
    "\n",
    "# 读取数据\n",
    "df = pd.read_csv('result_data_7.csv')\n",
    "\n",
    "# 标签处理（增加空值过滤）\n",
    "def convert_tags(tags_str):\n",
    "    tags = re.split(r'[，,]+', tags_str.strip())\n",
    "    valid_tags = [str(tag2id[tag]) for tag in tags if tag in tag2id]\n",
    "    return valid_tags if valid_tags else None  # 返回None用于后续过滤\n",
    "\n",
    "df['tags_ids'] = df['Tags'].apply(convert_tags)\n",
    "\n",
    "# 过滤无效数据（重要修复）\n",
    "print(f\"原始数据量: {len(df)}\")\n",
    "df = df.dropna(subset=['tags_ids'])  # 移除无有效标签的样本\n",
    "df = df[df['tags_ids'].apply(len) > 0]  # 移除标签为空的样本\n",
    "print(f\"有效数据量: {len(df)}\")\n",
    "\n",
    "# ==================== 条件过滤处理 ====================\n",
    "# 创建需要过滤的标签掩码\n",
    "mask = df['tags_ids'].apply(lambda tags: any(tag in {'0','3', '5','6'} for tag in tags))\n",
    "\n",
    "# 文本处理（仅对指定标签进行过滤）\n",
    "text_columns = ['Title', 'Abstract', 'Keywords']\n",
    "for col in text_columns:\n",
    "    df[col] = df[col].fillna('')\n",
    "    df.loc[mask, col] = df.loc[mask, col].apply(remove_high_freq)\n",
    "\n",
    "# 合并文本字段并二次清洗\n",
    "df['text'] = df[text_columns].apply(\n",
    "    lambda x: re.sub(r'\\s+', ' ', ' '.join(x)).strip(), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ==================== 数据划分 ====================\n",
    "y = np.zeros((len(df), len(tags_list)), dtype=int)\n",
    "for i, tags in enumerate(df['tags_ids']):\n",
    "    for tag in tags:\n",
    "        y[i, int(tag)] = 1\n",
    "\n",
    "X = df.index.values.reshape(-1, 1)\n",
    "X_train, y_train, X_temp, y_temp = iterative_train_test_split(X, y, test_size=0.3)\n",
    "X_val, y_val, X_test, y_test = iterative_train_test_split(X_temp, y_temp, test_size=0.5)\n",
    "\n",
    "# ==================== 数据保存（增加格式验证） ====================\n",
    "def save_dataset(df, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for text, tags in zip(df['text'], df['tags_ids']):\n",
    "            # 最终格式检查\n",
    "            if '\\t' in text:\n",
    "                text = text.replace('\\t', ' ')  # 确保文本不含制表符\n",
    "            line = f\"{text}\\t{','.join(tags)}\\n\"\n",
    "            assert line.count('\\t') == 1, f\"格式错误: {line}\"\n",
    "            f.write(line)\n",
    "\n",
    "train_df = df.iloc[X_train.flatten()]\n",
    "val_df = df.iloc[X_val.flatten()]\n",
    "test_df = df.iloc[X_test.flatten()]\n",
    "\n",
    "save_dataset(train_df, 'train.txt')\n",
    "save_dataset(val_df, 'dev.txt')\n",
    "save_dataset(test_df, 'test.txt')\n",
    "\n",
    "# ==================== 验证输出 ====================\n",
    "print(\"\\n处理完成！样本分布：\")\n",
    "print(f\"训练集: {len(train_df)}条\")\n",
    "print(f\"验证集: {len(val_df)}条\")\n",
    "print(f\"测试集: {len(test_df)}条\")\n",
    "\n",
    "# 验证数据格式\n",
    "def check_file(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if line.count('\\t') != 1:\n",
    "                print(f\"格式错误行 {i+1}: {line.strip()}\")\n",
    "\n",
    "print(\"\\n格式验证：\")\n",
    "check_file('train.txt')\n",
    "check_file('dev.txt')\n",
    "check_file('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf28ab02-adc5-463e-8a31-db7fd3178639",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-05-25T10:52:24.159603Z",
     "iopub.status.busy": "2025-05-25T10:52:24.159284Z",
     "iopub.status.idle": "2025-05-25T10:52:30.876030Z",
     "shell.execute_reply": "2025-05-25T10:52:30.875473Z",
     "shell.execute_reply.started": "2025-05-25T10:52:24.159582Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据量: 12717\n",
      "有效数据量: 12717\n",
      "\n",
      "处理完成！样本分布：\n",
      "训练集: 8902条\n",
      "验证集: 1906条\n",
      "测试集: 1909条\n",
      "\n",
      "格式验证：\n"
     ]
    }
   ],
   "source": [
    "#增加关键词增强\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "# ==================== 高频词过滤配置 ====================\n",
    "HIGH_FREQ_WORDS = {\n",
    "    '机器', '汽油', '气油', '能', '控', '系', '统', '技', '电', '动', '车', \n",
    "    '测', '试', '装', '备', '产', '造', '究', '物', '理', '源', '气', '管', \n",
    "    '化', '铁', '金', '钢', '高', '带', '液', '修', '强', '和', '中', '材', \n",
    "    '设', '托', '体', '氧', '于', '特', '地', '成', '型', '铝', '该', '光', \n",
    "    '继', '抗', '孔', '养', '上', '列', '头', '智', '应', '面', '基', '箱', \n",
    "    '自', '台', '人', '属', '空', '瓶', '种', '锁', '收', '片', '口', '米', \n",
    "    '联', '频', '断', '息', '计', '别', '活', '验', '瞬', '制', '据', '处', \n",
    "    '然', '保', '废', '配', '蒸', '数', '层', '绿', '向', '清', '盐', '压', \n",
    "    '加', '号', '发', '质', '池', '油', '氟', '震', '长', '集', '输', '感', \n",
    "    '水', '性', '警', '轮', '学', '挡', '建', '轴', '络', '内', '环', '温', \n",
    "    '检', '式', '品', '结', '合', '信','项目', '实现', '方法', '技术', '研究', \n",
    "    '具有', '提出', '采用', '通过','成果', '所述', '结果', '包括', '提供', \n",
    "    '解决', '评价', '中国', '系统','应用', '影响', '形成','问题','重庆市','创新',\n",
    "    '进行','关键','主要'\n",
    "}\n",
    "\n",
    "# ==================== 关键词替换逻辑 ====================\n",
    "# 解析keyword.txt构建替换规则\n",
    "category_keywords = {}\n",
    "current_category = None\n",
    "with open('keyword.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line.startswith('#'):\n",
    "            current_category = line[1:]\n",
    "            category_keywords[current_category] = []\n",
    "        else:\n",
    "            if current_category and line:\n",
    "                category_keywords[current_category].append(line)\n",
    "\n",
    "# 生成替换字典（关键词 -> 重复后的字符串）\n",
    "replace_dict = {}\n",
    "for category, keywords in category_keywords.items():\n",
    "    # 按长度降序排列避免短词优先匹配\n",
    "    keywords_sorted = sorted(keywords, key=lambda x: len(x), reverse=True)\n",
    "    # 根据出现顺序计算重复次数（前4个分别重复4/3/2/1次，后续重复1次）\n",
    "    for idx, word in enumerate(keywords_sorted):\n",
    "        repeat = max(8 - idx, 1)\n",
    "        replace_dict[word] = word * repeat\n",
    "\n",
    "# 构建正则表达式（按关键词长度降序匹配）\n",
    "sorted_keywords = sorted(replace_dict.keys(), key=lambda x: -len(x))\n",
    "keyword_pattern = re.compile('|'.join(map(re.escape, sorted_keywords)))\n",
    "\n",
    "def keyword_replacer(text):\n",
    "    \"\"\"关键词重复替换函数\"\"\"\n",
    "    return keyword_pattern.sub(lambda x: replace_dict[x.group()], text)\n",
    "\n",
    "# ==================== 核心过滤函数 ====================\n",
    "def remove_high_freq(text):\n",
    "    text = re.sub(r'[\\t\\n\\r]', ' ', text)\n",
    "    for word in HIGH_FREQ_WORDS:\n",
    "        text = text.replace(word, '')\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# ==================== 数据加载与预处理 ====================\n",
    "tags_list = [\n",
    "    \"传感器与仪器\",\n",
    "    \"生命健康技术\",\n",
    "    \"新材料科技\",\n",
    "    \"新能源与动力\",\n",
    "    \"数字智能技术\",\n",
    "    \"智能制造与装备\",\n",
    "    \"其它\"   \n",
    "]\n",
    "tag2id = {tag: idx for idx, tag in enumerate(tags_list)}\n",
    "\n",
    "df = pd.read_csv('result_data_7.csv')\n",
    "\n",
    "# 标签处理\n",
    "def convert_tags(tags_str):\n",
    "    tags = re.split(r'[，,]+', tags_str.strip())\n",
    "    valid_tags = [str(tag2id[tag]) for tag in tags if tag in tag2id]\n",
    "    return valid_tags if valid_tags else None\n",
    "\n",
    "df['tags_ids'] = df['Tags'].apply(convert_tags)\n",
    "\n",
    "# 过滤无效数据\n",
    "print(f\"原始数据量: {len(df)}\")\n",
    "df = df.dropna(subset=['tags_ids'])\n",
    "df = df[df['tags_ids'].apply(len) > 0]\n",
    "print(f\"有效数据量: {len(df)}\")\n",
    "\n",
    "# ==================== 条件过滤处理 ====================\n",
    "mask = df['tags_ids'].apply(lambda tags: any(tag in {'3', '5','6'} for tag in tags))\n",
    "\n",
    "text_columns = ['Title', 'Abstract', 'Keywords']\n",
    "for col in text_columns:\n",
    "    df[col] = df[col].fillna('')\n",
    "    df.loc[mask, col] = df.loc[mask, col].apply(remove_high_freq)\n",
    "\n",
    "# 合并文本字段\n",
    "df['raw_text'] = df[text_columns].apply(\n",
    "    lambda x: re.sub(r'\\s+', ' ', ' '.join(x)).strip(), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 应用关键词替换（在最终文本上处理）\n",
    "df['text'] = df['raw_text'].apply(keyword_replacer)\n",
    "\n",
    "# ==================== 数据划分 ====================\n",
    "y = np.zeros((len(df), len(tags_list)), dtype=int)\n",
    "for i, tags in enumerate(df['tags_ids']):\n",
    "    for tag in tags:\n",
    "        y[i, int(tag)] = 1\n",
    "\n",
    "X = df.index.values.reshape(-1, 1)\n",
    "X_train, y_train, X_temp, y_temp = iterative_train_test_split(X, y, test_size=0.3)\n",
    "X_val, y_val, X_test, y_test = iterative_train_test_split(X_temp, y_temp, test_size=0.5)\n",
    "\n",
    "# ==================== 数据保存 ====================\n",
    "def save_dataset(df, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for text, tags in zip(df['text'], df['tags_ids']):\n",
    "            line = f\"{text}\\t{','.join(tags)}\\n\"\n",
    "            assert line.count('\\t') == 1, f\"格式错误: {line}\"\n",
    "            f.write(line)\n",
    "\n",
    "train_df = df.iloc[X_train.flatten()]\n",
    "val_df = df.iloc[X_val.flatten()]\n",
    "test_df = df.iloc[X_test.flatten()]\n",
    "\n",
    "save_dataset(train_df, 'train.txt')\n",
    "save_dataset(val_df, 'dev.txt')\n",
    "save_dataset(test_df, 'test.txt')\n",
    "\n",
    "# ==================== 验证输出 ====================\n",
    "print(\"\\n处理完成！样本分布：\")\n",
    "print(f\"训练集: {len(train_df)}条\")\n",
    "print(f\"验证集: {len(val_df)}条\")\n",
    "print(f\"测试集: {len(test_df)}条\")\n",
    "\n",
    "def check_file(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if line.count('\\t') != 1:\n",
    "                print(f\"格式错误行 {i+1}: {line.strip()}\")\n",
    "\n",
    "print(\"\\n格式验证：\")\n",
    "check_file('train.txt')\n",
    "check_file('dev.txt')\n",
    "check_file('test.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
